import 'dart:async';
import 'dart:math';
import 'dart:ui' as ui;
import 'package:flutter/material.dart';
import 'package:battery_plus/battery_plus.dart';
import 'package:url_launcher/url_launcher.dart';

import 'rtsp_bridge.dart';
import 'ocr_service.dart';
import 'detector_yolo.dart';
import 'tts_haptics.dart';
import 'config/context_manager.dart';
import 'risk_logic.dart';
import 'gps_service.dart';
import 'places_service.dart';
import 'number_extractor.dart';
import 'voice_command.dart';
// import 'face_service.dart'; // b·∫≠t n·∫øu d√πng nh·∫≠n di·ªán

void main()=> runApp(const App());

class App extends StatelessWidget {
  const App({super.key});
  @override Widget build(BuildContext c)=> const MaterialApp(debugShowCheckedModeBanner:false, home: Home());
}

class Home extends StatefulWidget { const Home({super.key}); @override State<Home> createState()=>_HomeState(); }

class _HomeState extends State<Home>{
  final rtsp=RtspBridge(); final ocr=OcrService(); final ntf=Notifier();
  final battery=Battery(); final ctxMgr=ContextManager(); final gps=GpsService();
  final places=PlacesService(); final voice=VoiceCommand();
  // final face=FaceService();
  late YOLOv8n det;

  String activeProfile='scan_outdoor'; bool obstacleMode=true; bool busy=false; bool powerSave=false; bool sosMode=false;
  double kDistance=1400;

  @override void initState(){ super.initState(); rtsp.onFrame=_onFrame; _boot(); }

  Future<void> _boot() async {
    await ctxMgr.load(); await gps.init(); await places.init(); await voice.init(); // await face.init();
    _applyProfile('scan_outdoor');
    det = await YOLOv8n.create(modelAsset:'assets/models/detector.tflite', labelsAsset:'assets/models/labels.txt',
      inputSize:320, scoreThresh:0.55, nmsIou:0.5, topK:50);
    await rtsp.start('rtsp://192.168.50.1:8554/unicast');
    final lvl = await battery.batteryLevel; if(lvl<25) _setPowerSave(true);
  }

  void _applyProfile(String name){
    final p=ctxMgr.get(name); activeProfile=name; rtsp.setIntervalMs(p.snapshotMs);
    ntf.minGapSec=p.ttsGapSec; kDistance=p.kDistance; setState((){});
  }

  void _setPowerSave(bool on){ powerSave=on; _applyProfile(on?'power_save':'scan_outdoor'); }

  Future<void> _onFrame(ui.Image img) async {
    if(!obstacleMode || busy) return; busy=true;
    try{
      final dets=await det.detect(img); final p=ctxMgr.get(activeProfile);
      final filtered=dets.where((d)=> p.classes.contains(d.cls)).toList();
      if(filtered.isNotEmpty){
        filtered.sort((a,b)=> _dist(a).compareTo(_dist(b)));
        final top=filtered.first; final dist=_dist(top);
        final side=bearingOf(top.x1,top.x2,img.width.toDouble());
        final lvl=riskLevel(top.cls,dist,side,conf: top.score);
        if(lvl>0){
          await ntf.buzz(lvl);
          final name=viName(top.cls); final word=dist<1.2?'r·∫•t g·∫ßn':(dist<2.5?'g·∫ßn':'xa');
          final msg=(lvl>=3)?'D·ª´ng l·∫°i! Ph√≠a $side r·∫•t g·∫ßn $name.':'Ph√≠a $side c√≥ $name, $word.';
          await ntf.say(msg);
        }
      }
    } finally { busy=false; }
  }

  double _dist(d){ final h=max(1.0,d.y2-d.y1); return kDistance/h; }

  Future<void> _doOCR() async {
    obstacleMode=false;
    final shot = await _grabOne();
    final text = await ocr.recognize(shot);
    await ntf.say(text.isEmpty? 'Kh√¥ng th·∫•y ch·ªØ r√µ.' : 'N·ªôi dung: $text');
    final meta=NumberExtractor.extractAll(text); await ntf.say(NumberExtractor.speak(meta));
    obstacleMode=true; setState((){});
  }

  Future<ui.Image> _grabOne() async {
    final c=Completer<ui.Image>(); final prev=rtsp.onFrame; rtsp.onFrame=(img){ rtsp.onFrame=prev; c.complete(img); };
    return c.future;
  }

  Future<void> _speakLocation() async {
    final pos=await gps.current(); if(pos==null){ await ntf.say('Kh√¥ng l·∫•y ƒë∆∞·ª£c v·ªã tr√≠.'); return; }
    await ntf.say(GpsService.speakable(pos.latitude,pos.longitude));
    final addr=await gps.reverse(pos.latitude,pos.longitude); if(addr!=null&&addr.trim().isNotEmpty) await ntf.say('G·∫ßn: $addr');
  }

  Future<void> _toggleSOS() async {
    sosMode=!sosMode;
    if(sosMode){ await ntf.say('K√≠ch ho·∫°t S O S.'); await _speakLocation(); }
    else { await ntf.say('T·∫Øt S O S.'); }
    setState((){});
  }

  Future<void> _saveCurrentPlace(String name) async {
    final pos=await gps.current(); if(pos==null){ await ntf.say('Kh√¥ng l·∫•y ƒë∆∞·ª£c v·ªã tr√≠.'); return; }
    await places.savePlace(name.isEmpty?'Noi_${DateTime.now().millisecondsSinceEpoch}':name, pos.latitude,pos.longitude);
    await ntf.say('ƒê√£ l∆∞u n∆°i $name.');
  }

  double _hav(double lat1,double lon1,double lat2,double lon2){
    const R=6371000.0; final dLat=(lat2-lat1)*pi/180, dLon=(lon2-lon1)*pi/180;
    final a=sin(dLat/2)*sin(dLat/2)+cos(lat1*pi/180)*cos(lat2*pi/180)*sin(dLon/2)*sin(dLon/2);
    return R*2*atan2(sqrt(a),sqrt(1-a));
  }
  double _bearing(double lat1,double lon1,double lat2,double lon2){
    final y=sin((lon2-lon1)*pi/180)*cos(lat2*pi/180);
    final x=cos(lat1*pi/180)*sin(lat2*pi/180)-sin(lat1*pi/180)*cos(lat2*pi/180)*cos((lon2-lon1)*pi/180);
    var b=atan2(y,x)*180/pi; if(b<0) b+=360; return b;
  }

  Future<void> _gotoPlace(SavedPlace p) async {
    final pos=await gps.current(); if(pos==null){ await ntf.say('Kh√¥ng l·∫•y ƒë∆∞·ª£c v·ªã tr√≠.'); return; }
    final d=_hav(pos.latitude,pos.longitude,p.lat,p.lon); final b=_bearing(pos.latitude,pos.longitude,p.lat,p.lon);
    final dir=(b<30||b>=330)?'B·∫Øc': (b<60)?'ƒê√¥ng B·∫Øc': (b<120)?'ƒê√¥ng': (b<150)?'ƒê√¥ng Nam': (b<210)?'Nam': (b<240)?'T√¢y Nam': (b<300)?'T√¢y':'T√¢y B·∫Øc';
    await ntf.say('N∆°i ${p.name}: c√°ch kho·∫£ng ${d.round()} m√©t, h∆∞·ªõng $dir.');
    final url=Uri.parse('https://maps.google.com/?q=${p.lat},${p.lon}');
    await launchUrl(url, mode: LaunchMode.externalApplication);
  }

  Future<void> _handleVoiceCommand(String s) async {
    s=s.toLowerCase().replaceAll(RegExp(r'\s+'),' ').trim();
    if(s.contains('ƒë·ªçc ch·ªØ')||s.contains('ocr')) { await _doOCR(); return; }
    if(s.contains('y√™n l·∫∑ng')) { _applyProfile('quiet_mode'); await ntf.say('ƒê√£ b·∫≠t y√™n l·∫∑ng'); return; }
    if(s.contains('ti·∫øt ki·ªám')||s.contains('power')) { _setPowerSave(true); await ntf.say('ƒê√£ b·∫≠t ti·∫øt ki·ªám pin'); return; }
    if(s.contains('t·∫Øt ti·∫øt ki·ªám')) { _setPowerSave(false); await ntf.say('ƒê√£ t·∫Øt ti·∫øt ki·ªám pin'); return; }
    if(s.contains('ngo√†i tr·ªùi')) { _applyProfile('scan_outdoor'); await ntf.say('ƒê√£ chuy·ªÉn ngo√†i tr·ªùi'); return; }
    if(s.contains('trong nh√†')) { _applyProfile('scan_indoor'); await ntf.say('ƒê√£ chuy·ªÉn trong nh√†'); return; }
    if(s.contains('qua ƒë∆∞·ªùng')) { _applyProfile('crosswalk'); await ntf.say('ƒê√£ chuy·ªÉn qua ƒë∆∞·ªùng'); return; }
    if(s.contains('s o s')||s.contains('kh·∫©n c·∫•p')) { await _toggleSOS(); return; }
    if(s.contains('v·ªã tr√≠ c·ªßa t√¥i')||s.contains('t√¥i ƒëang ·ªü ƒë√¢u')) { await _speakLocation(); return; }
    if(s.startsWith('l∆∞u n∆°i')) { final name=s.replaceFirst('l∆∞u n∆°i','').trim(); await _saveCurrentPlace(name); return; }
    if(s.startsWith('ƒëi t·ªõi')||s.startsWith('ƒëi ƒë·∫øn')){
      final name=s.replaceFirst(RegExp(r'ƒëi (t·ªõi|ƒë·∫øn)'),'').trim();
      final item = places.list().reversed.firstWhere((p)=> p.name.toLowerCase()==name.toLowerCase(), orElse: ()=> places.list().isEmpty? null: places.list().last);
      if(item==null){ await ntf.say('Ch∆∞a c√≥ n∆°i ƒë√£ l∆∞u.'); return; } await _gotoPlace(item); return;
    }
    await ntf.say('B·∫°n c√≥ th·ªÉ n√≥i: ƒë·ªçc ch·ªØ, y√™n l·∫∑ng, ti·∫øt ki·ªám, ngo√†i tr·ªùi, trong nh√†, qua ƒë∆∞·ªùng, v·ªã tr√≠ c·ªßa t√¥i, l∆∞u n∆°i <t√™n>, ƒëi t·ªõi <t√™n>, S O S.');
  }

  @override Widget build(BuildContext c){
    final profiles=ctxMgr.list();
    return Scaffold(
      backgroundColor: Colors.black,
      body: SafeArea(child: Column(children:[
        const SizedBox(height:10),
        const Text('K√≠nh tr·ª£ l·ª±c (Bluetooth mic/speaker) ‚Äì YOLOv8n', style: TextStyle(color:Colors.white,fontSize:18)),
        const SizedBox(height:10),
        Wrap(spacing:8, runSpacing:8, alignment: WrapAlignment.center, children:[
          ElevatedButton(onPressed:_doOCR, child: const Text('ƒê·ªçc ch·ªØ')),
          ElevatedButton(onPressed: ()=> setState(()=> obstacleMode=!obstacleMode), child: Text(obstacleMode?'T·∫°m d·ª´ng d√≤':'Ti·∫øp t·ª•c d√≤')),
          ElevatedButton(onPressed: ()=> setState(()=> _setPowerSave(!powerSave)), child: Text(powerSave?'T·∫Øt Power Save':'B·∫≠t Power Save')),
          ElevatedButton(onPressed: _speakLocation, child: const Text('V·ªã tr√≠ c·ªßa t√¥i')),
          ElevatedButton(onPressed: _toggleSOS, child: Text(sosMode?'T·∫Øt SOS':'B·∫≠t SOS')),
          ElevatedButton(onPressed: ()=> _saveCurrentPlace('Noi_${DateTime.now().millisecondsSinceEpoch}'), child: const Text('L∆∞u n∆°i n√†y')),
          ElevatedButton(onPressed: () async { final items=places.list(); if(items.isEmpty){ await ntf.say('Ch∆∞a c√≥ n∆°i n√†o.'); return; } await _gotoPlace(items.last); }, child: const Text('Danh s√°ch n∆°i')),
          ElevatedButton(onPressed: () async { await ntf.say('ƒêang nghe...'); await voice.listenVI(_handleVoiceCommand); }, child: const Text('üé§ Gi·ªçng n√≥i')),
          DropdownButton<String>(
            dropdownColor: Colors.grey[900], value: activeProfile, style: const TextStyle(color:Colors.white),
            items: profiles.map((e)=> DropdownMenuItem(value:e, child: Text(e, style: const TextStyle(color:Colors.white)))).toList(),
            onChanged: (v){ if(v!=null) _applyProfile(v); })
        ])
      ]))
    );
  }
  final face = FaceService();

@override
Future<void> _boot() async {
   ...
   await face.init();
}

Future<void> _enrollFace(String name) async {
  final shot = await _grabOne();
  try {
    await face.enroll(name, shot);
    await ntf.say("ƒê√£ l∆∞u m·∫∑t $name.");
  } catch (e) {
    await ntf.say("Kh√¥ng th·ªÉ l∆∞u m·∫∑t.");
  }
}

Future<void> _identifyFace() async {
  final shot = await _grabOne();
  final who = await face.identify(shot);
  if (who == null) await ntf.say("Kh√¥ng nh·∫≠n ra ai.");
  else await ntf.say("ƒê√¢y l√† $who.");
}
}
